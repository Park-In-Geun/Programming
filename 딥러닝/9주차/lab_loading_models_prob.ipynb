{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab_loading_models_prob_20145128_박인근.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baSdgBNI7re7"
      },
      "source": [
        "# Part 1: Saving and Loading Models\n",
        "\n",
        "* 이번 실습에서는 model을 저장하고 불러오는 방법에 대해서 하겠습니다\n",
        "* 저장과 불러오기를 학습하는 것이 중요한 이유는, 많은 경우 사전에 training이 완료된 모델을 불러와서 사용할 수있어야 하기 때문입니다\n",
        "* 그럼 실습을 차근차근 해볼까요~\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lki_CLvA7re9"
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import myhelper\n",
        "import fc_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GW6BFH8P7rfD"
      },
      "source": [
        "#### `fc_model`\n",
        "* 위에서 마지막 줄을 보시면 fc_model 이라는 모듈이 있습니다\n",
        "* 실습의 편의상 제공하는 fc_model.py 파일안에 정의가 되어 있습니다 (한번 살펴보시죠) \n",
        "* 사용 방법 `fc_model(input_size, output_size, hidden_layers, drop_p=0.5)`\n",
        "  * `input_size`는 input 벡터의 크기\n",
        "  * `output_size`는 output 벡터의 크기\n",
        "  * `hidden_layers` **list**로 hidden layer들의 크기를 저장합니다\n",
        "    * 예를 들어서 `hidden_layers=[256, 128, 64]` 라 하면\n",
        "    * hidden layer를 3개 각각 256, 128 64의 크기로 만들어 줍니다.\n",
        "  * 즉 전체적으로 네트워크를 아래와 같이 구성합니다:\n",
        "  ```\n",
        "     hidden_1 = nn.Linear(input_size, 256)\n",
        "     hidden_2 = nn.Linear(256, 128)\n",
        "     hidden_3 = nn.Linear(128, output_size)\n",
        "  ```\n",
        "  * 모든 hidden layer의 activation은 `F.relu` 입니다\n",
        "  * output layer의 activation 함수는 `F.log_softmax`를 적용합니다\n",
        "  * 모든 hidden layer에 dropout을 `drop_p` 확률로 적용합니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRNlexrA7rfG"
      },
      "source": [
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,))])\n",
        "# Download and load the training data\n",
        "trainset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Download and load the test data\n",
        "testset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bmg8WCZs7rfL"
      },
      "source": [
        "* 이미지 한개 샘플을 살펴봅니다 (이미 익숙한 그림입니다)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjG5o3-g7rfM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "007aa8b7-4f8e-4fdd-c7de-b43dcdd3702e"
      },
      "source": [
        "image, label = next(iter(trainloader))\n",
        "myhelper.imshow(image[0,:]);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 231,
              "height": 231
            },
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXuDw6PZ7rfR"
      },
      "source": [
        "# Train a network\n",
        "\n",
        "To make things more concise here, I moved the model architecture and training code from the last part to a file called `fc_model`. Importing this, we can easily create a fully-connected network with `fc_model.Network`, and train the network using `fc_model.train`. I'll use this model (once it's trained) to demonstrate how we can save and load models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2-gVOOC7rfS"
      },
      "source": [
        "# Create the network, define the criterion and optimizer\n",
        "\n",
        "model = fc_model.Network(784, 10, [512, 256, 128])\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDkyPMFh7rfV",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        },
        "outputId": "f6d94272-6a16-4b2b-a3b4-ee3295fbde98"
      },
      "source": [
        "fc_model.train(model, trainloader, testloader, criterion, optimizer, epochs=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/2..  Training Loss: 1.701..  Test Loss: 0.985..  Test Accuracy: 0.666\n",
            "Epoch: 1/2..  Training Loss: 1.024..  Test Loss: 0.713..  Test Accuracy: 0.734\n",
            "Epoch: 1/2..  Training Loss: 0.823..  Test Loss: 0.666..  Test Accuracy: 0.748\n",
            "Epoch: 1/2..  Training Loss: 0.835..  Test Loss: 0.649..  Test Accuracy: 0.751\n",
            "Epoch: 1/2..  Training Loss: 0.738..  Test Loss: 0.601..  Test Accuracy: 0.772\n",
            "Epoch: 1/2..  Training Loss: 0.711..  Test Loss: 0.624..  Test Accuracy: 0.768\n",
            "Epoch: 1/2..  Training Loss: 0.686..  Test Loss: 0.562..  Test Accuracy: 0.786\n",
            "Epoch: 1/2..  Training Loss: 0.667..  Test Loss: 0.561..  Test Accuracy: 0.788\n",
            "Epoch: 1/2..  Training Loss: 0.653..  Test Loss: 0.538..  Test Accuracy: 0.802\n",
            "Epoch: 1/2..  Training Loss: 0.637..  Test Loss: 0.540..  Test Accuracy: 0.803\n",
            "Epoch: 1/2..  Training Loss: 0.618..  Test Loss: 0.544..  Test Accuracy: 0.801\n",
            "Epoch: 1/2..  Training Loss: 0.592..  Test Loss: 0.523..  Test Accuracy: 0.806\n",
            "Epoch: 1/2..  Training Loss: 0.607..  Test Loss: 0.521..  Test Accuracy: 0.804\n",
            "Epoch: 1/2..  Training Loss: 0.613..  Test Loss: 0.539..  Test Accuracy: 0.803\n",
            "Epoch: 1/2..  Training Loss: 0.613..  Test Loss: 0.509..  Test Accuracy: 0.810\n",
            "Epoch: 1/2..  Training Loss: 0.578..  Test Loss: 0.505..  Test Accuracy: 0.810\n",
            "Epoch: 1/2..  Training Loss: 0.589..  Test Loss: 0.523..  Test Accuracy: 0.812\n",
            "Epoch: 1/2..  Training Loss: 0.609..  Test Loss: 0.503..  Test Accuracy: 0.818\n",
            "Epoch: 1/2..  Training Loss: 0.578..  Test Loss: 0.503..  Test Accuracy: 0.819\n",
            "Epoch: 1/2..  Training Loss: 0.573..  Test Loss: 0.494..  Test Accuracy: 0.816\n",
            "Epoch: 1/2..  Training Loss: 0.575..  Test Loss: 0.501..  Test Accuracy: 0.810\n",
            "Epoch: 1/2..  Training Loss: 0.573..  Test Loss: 0.493..  Test Accuracy: 0.820\n",
            "Epoch: 1/2..  Training Loss: 0.597..  Test Loss: 0.479..  Test Accuracy: 0.824\n",
            "Epoch: 2/2..  Training Loss: 0.550..  Test Loss: 0.490..  Test Accuracy: 0.819\n",
            "Epoch: 2/2..  Training Loss: 0.542..  Test Loss: 0.479..  Test Accuracy: 0.826\n",
            "Epoch: 2/2..  Training Loss: 0.540..  Test Loss: 0.469..  Test Accuracy: 0.826\n",
            "Epoch: 2/2..  Training Loss: 0.574..  Test Loss: 0.460..  Test Accuracy: 0.833\n",
            "Epoch: 2/2..  Training Loss: 0.532..  Test Loss: 0.473..  Test Accuracy: 0.825\n",
            "Epoch: 2/2..  Training Loss: 0.561..  Test Loss: 0.477..  Test Accuracy: 0.833\n",
            "Epoch: 2/2..  Training Loss: 0.523..  Test Loss: 0.467..  Test Accuracy: 0.829\n",
            "Epoch: 2/2..  Training Loss: 0.555..  Test Loss: 0.465..  Test Accuracy: 0.833\n",
            "Epoch: 2/2..  Training Loss: 0.495..  Test Loss: 0.460..  Test Accuracy: 0.826\n",
            "Epoch: 2/2..  Training Loss: 0.499..  Test Loss: 0.461..  Test Accuracy: 0.832\n",
            "Epoch: 2/2..  Training Loss: 0.540..  Test Loss: 0.464..  Test Accuracy: 0.829\n",
            "Epoch: 2/2..  Training Loss: 0.535..  Test Loss: 0.452..  Test Accuracy: 0.836\n",
            "Epoch: 2/2..  Training Loss: 0.499..  Test Loss: 0.460..  Test Accuracy: 0.833\n",
            "Epoch: 2/2..  Training Loss: 0.568..  Test Loss: 0.445..  Test Accuracy: 0.843\n",
            "Epoch: 2/2..  Training Loss: 0.519..  Test Loss: 0.443..  Test Accuracy: 0.838\n",
            "Epoch: 2/2..  Training Loss: 0.508..  Test Loss: 0.454..  Test Accuracy: 0.828\n",
            "Epoch: 2/2..  Training Loss: 0.549..  Test Loss: 0.455..  Test Accuracy: 0.833\n",
            "Epoch: 2/2..  Training Loss: 0.524..  Test Loss: 0.460..  Test Accuracy: 0.837\n",
            "Epoch: 2/2..  Training Loss: 0.516..  Test Loss: 0.444..  Test Accuracy: 0.837\n",
            "Epoch: 2/2..  Training Loss: 0.520..  Test Loss: 0.437..  Test Accuracy: 0.840\n",
            "Epoch: 2/2..  Training Loss: 0.537..  Test Loss: 0.453..  Test Accuracy: 0.838\n",
            "Epoch: 2/2..  Training Loss: 0.489..  Test Loss: 0.452..  Test Accuracy: 0.834\n",
            "Epoch: 2/2..  Training Loss: 0.524..  Test Loss: 0.437..  Test Accuracy: 0.838\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-Mgo6v47rfb"
      },
      "source": [
        "## Saving and loading networks\n",
        "\n",
        "* 1차적으로 *저장하기*가 유용한 이유는 생각해보실 수 있죠? 우리가 training이 된 네트워크를 통해서 예측을 하고자 하는데, 매번 training을 할 수도, 이유도 없죠\n",
        "* 대신에 training이 완료된 모델을 저장하고, 활용하고자 할때 불러와서 사용하면 유용하겠죠?\n",
        "* Pytorch에서 우리가 training을 통해서 얻은 parameter들은 `state_dict`라는 형태로 자장됩니다\n",
        "  * 즉 네트워크의 weight와 bias들이 각 layer 별로 저장됩니다. 아래 확인해보죠\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxVPPINL7rfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "9ce7bb40-77dc-42f4-8922-820943d32de5"
      },
      "source": [
        "print(\"Our model: \\n\\n\", model, '\\n')\n",
        "print(\"The state dict keys: \\n\\n\", model.state_dict().keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our model: \n",
            "\n",
            " Network(\n",
            "  (hidden_layers): ModuleList(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
            "  )\n",
            "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ") \n",
            "\n",
            "The state dict keys: \n",
            "\n",
            " odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'hidden_layers.2.weight', 'hidden_layers.2.bias', 'output.weight', 'output.bias'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQZMRI6GRGL6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "56b5ab0b-db49-45d5-b11b-8bcce93cb13b"
      },
      "source": [
        "model.state_dict()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('hidden_layers.0.weight',\n",
              "              tensor([[-0.0020,  0.0081, -0.0108,  ...,  0.0464,  0.0418,  0.0139],\n",
              "                      [-0.0129, -0.0084,  0.0238,  ..., -0.0263,  0.0064, -0.0177],\n",
              "                      [ 0.0226,  0.0616,  0.0441,  ...,  0.0254,  0.0684,  0.0248],\n",
              "                      ...,\n",
              "                      [ 0.0153,  0.0163, -0.0010,  ..., -0.0100,  0.0043, -0.0117],\n",
              "                      [ 0.0081,  0.0317,  0.0391,  ..., -0.0102,  0.0412,  0.0303],\n",
              "                      [ 0.0453,  0.0390,  0.0226,  ...,  0.0549,  0.0212,  0.0313]])),\n",
              "             ('hidden_layers.0.bias',\n",
              "              tensor([ 0.0185,  0.0036, -0.0575,  0.0081, -0.0528, -0.0367,  0.0118, -0.0148,\n",
              "                      -0.0351, -0.0378, -0.0493, -0.0890, -0.0208,  0.0003, -0.0051, -0.0498,\n",
              "                      -0.0128, -0.0621,  0.0070, -0.0110,  0.0055, -0.0666, -0.0290,  0.0176,\n",
              "                      -0.0443, -0.0148, -0.0202, -0.0540, -0.0022, -0.0192, -0.0132,  0.0128,\n",
              "                      -0.0314,  0.0100, -0.0030,  0.0203,  0.0124, -0.0463, -0.0179, -0.0238,\n",
              "                       0.0143, -0.0256, -0.0225, -0.0250, -0.0528,  0.0135, -0.0240,  0.0030,\n",
              "                      -0.0096, -0.0284,  0.0057, -0.0490, -0.0315,  0.0143, -0.0264, -0.0065,\n",
              "                       0.0056, -0.0071, -0.0327, -0.0250,  0.0434, -0.0417, -0.0141, -0.0362,\n",
              "                      -0.0535,  0.0013, -0.0415, -0.0255, -0.0421, -0.0355, -0.0067,  0.0139,\n",
              "                      -0.0582,  0.0153, -0.0249, -0.0146, -0.0293, -0.0145, -0.0501, -0.0585,\n",
              "                      -0.0256,  0.0061, -0.0353, -0.0127, -0.0004, -0.0259, -0.0872, -0.0534,\n",
              "                      -0.0410, -0.0042,  0.0045, -0.0470, -0.0038,  0.0031, -0.0180, -0.0189,\n",
              "                      -0.0546,  0.0064, -0.0225,  0.0115, -0.0826,  0.0286,  0.0025, -0.0402,\n",
              "                      -0.0033,  0.0024, -0.0168,  0.0081, -0.0106, -0.0091,  0.0153, -0.0278,\n",
              "                       0.0034, -0.0292, -0.0158, -0.0489, -0.0194, -0.0083, -0.0183, -0.0035,\n",
              "                      -0.0347, -0.0171, -0.0232, -0.0371, -0.0597, -0.0365, -0.0063,  0.0071,\n",
              "                      -0.0493, -0.0479, -0.0251,  0.0207, -0.0112, -0.0437, -0.0226, -0.0136,\n",
              "                       0.0021,  0.0007, -0.0150, -0.0236, -0.0329, -0.0034, -0.0121, -0.0574,\n",
              "                      -0.0404, -0.0022, -0.0337,  0.0060, -0.0321, -0.0368, -0.0306,  0.0117,\n",
              "                       0.0520,  0.0024, -0.0279, -0.0464, -0.0494, -0.0300, -0.0429, -0.0374,\n",
              "                      -0.0435, -0.0350, -0.0581, -0.0437, -0.0001, -0.0297,  0.0095, -0.0400,\n",
              "                      -0.0215, -0.0153,  0.0044, -0.0096, -0.0314, -0.0876, -0.0188,  0.0007,\n",
              "                      -0.0110, -0.0441, -0.0309,  0.0117, -0.0065, -0.0484, -0.0358, -0.0339,\n",
              "                       0.0118, -0.0122,  0.0007, -0.0391, -0.0344,  0.0257,  0.0086, -0.0458,\n",
              "                      -0.0083, -0.0468, -0.0240, -0.0336, -0.0183,  0.0103, -0.0702, -0.0315,\n",
              "                      -0.0031,  0.0034, -0.0436, -0.0241, -0.0349, -0.0425, -0.0518,  0.0230,\n",
              "                      -0.0261,  0.0158,  0.0212, -0.0618, -0.0395, -0.0067, -0.0268,  0.0357,\n",
              "                       0.0197, -0.0354, -0.0411, -0.0483, -0.0103, -0.0315,  0.0062, -0.0272,\n",
              "                      -0.0039, -0.0429, -0.0378,  0.0021,  0.0262, -0.0293, -0.0177, -0.0363,\n",
              "                       0.0359, -0.0020, -0.0246, -0.0368, -0.0465, -0.0559, -0.0549, -0.0331,\n",
              "                      -0.0005, -0.0234, -0.0457,  0.0070, -0.0450, -0.0166, -0.0653,  0.0097,\n",
              "                       0.0314, -0.0313, -0.0241,  0.0062,  0.0243, -0.0289, -0.0312,  0.0197,\n",
              "                      -0.0076, -0.0430,  0.0058, -0.0521, -0.0260,  0.0197, -0.0383,  0.0154,\n",
              "                      -0.0321,  0.0008,  0.0034,  0.0052,  0.0111, -0.0176, -0.0069, -0.0223,\n",
              "                      -0.0512, -0.0128,  0.0102, -0.0326,  0.0102, -0.0378, -0.0223,  0.0066,\n",
              "                      -0.0028, -0.0634, -0.0285, -0.0605,  0.0225, -0.0158, -0.0017, -0.0062,\n",
              "                      -0.0374, -0.0413, -0.0216, -0.0204, -0.0130,  0.0065, -0.0520, -0.0561,\n",
              "                      -0.0634, -0.0190, -0.0265,  0.0097, -0.0369,  0.0199,  0.0033,  0.0074,\n",
              "                       0.0203, -0.0361, -0.0547, -0.0139,  0.0091, -0.0057, -0.0248, -0.0240,\n",
              "                       0.0016, -0.0454, -0.0327,  0.0012, -0.0426,  0.0245, -0.0502,  0.0160,\n",
              "                      -0.0134, -0.0273, -0.0190,  0.0224,  0.0135, -0.0294, -0.0739,  0.0096,\n",
              "                      -0.0406, -0.0188,  0.0122,  0.0172, -0.0281, -0.0094, -0.0095, -0.0325,\n",
              "                      -0.0447, -0.0073, -0.0582, -0.0066, -0.0238,  0.0027, -0.0046, -0.0437,\n",
              "                      -0.0748,  0.0100, -0.0043, -0.0232,  0.0318,  0.0040, -0.0038, -0.0334,\n",
              "                      -0.0440, -0.0428, -0.0284, -0.0131, -0.0240,  0.0096, -0.0005, -0.0468,\n",
              "                      -0.0467, -0.0360,  0.0166, -0.0470, -0.0860, -0.0282, -0.0264, -0.0395,\n",
              "                       0.0144, -0.0051,  0.0023, -0.0381,  0.0065,  0.0039, -0.0093,  0.0019,\n",
              "                       0.0094,  0.0140, -0.0151, -0.0126, -0.0291, -0.0624,  0.0146, -0.0283,\n",
              "                       0.0142,  0.0339, -0.0278, -0.0179, -0.0183, -0.0160, -0.0319, -0.0086,\n",
              "                      -0.0219,  0.0132, -0.0160, -0.0103, -0.0258,  0.0447, -0.0233, -0.0318,\n",
              "                       0.0022, -0.0068,  0.0101,  0.0174, -0.0508,  0.0106,  0.0051, -0.0500,\n",
              "                      -0.0579, -0.0209,  0.0040, -0.0479, -0.0369, -0.0343, -0.0290, -0.0348,\n",
              "                      -0.0133, -0.0032, -0.0300,  0.0069, -0.0563,  0.0310, -0.0614, -0.0514,\n",
              "                       0.0132, -0.0529,  0.0049, -0.0434,  0.0197, -0.0064, -0.0518,  0.0032,\n",
              "                      -0.0070, -0.0540, -0.0350, -0.0269, -0.0360, -0.0015, -0.0611, -0.0476,\n",
              "                      -0.0484, -0.0010,  0.0105, -0.0524, -0.0028, -0.0082, -0.0087, -0.0332,\n",
              "                      -0.0100,  0.0039, -0.0104, -0.0098, -0.0310, -0.0253, -0.0549, -0.0088,\n",
              "                      -0.0392, -0.0597,  0.0041, -0.0233, -0.0321, -0.0097,  0.0004, -0.0579,\n",
              "                      -0.0216, -0.0525, -0.0356, -0.0392, -0.0372, -0.0211, -0.0380, -0.0009,\n",
              "                      -0.0187,  0.0209, -0.0443,  0.0023,  0.0057, -0.0130,  0.0064,  0.0400,\n",
              "                      -0.0064, -0.0339, -0.0381, -0.0425,  0.0091,  0.0056, -0.0058,  0.0131,\n",
              "                      -0.0137, -0.0388,  0.0578, -0.0547, -0.0437, -0.0154, -0.0264, -0.0319,\n",
              "                      -0.0371, -0.0759,  0.0066,  0.0149, -0.0449, -0.0531, -0.0565, -0.0075,\n",
              "                       0.0066, -0.0354, -0.0450,  0.0099, -0.0368, -0.0025, -0.0056, -0.0305])),\n",
              "             ('hidden_layers.1.weight',\n",
              "              tensor([[-0.0316, -0.0317, -0.0344,  ...,  0.0557, -0.0636, -0.0307],\n",
              "                      [ 0.0417, -0.0355, -0.0587,  ..., -0.0119, -0.0016, -0.0467],\n",
              "                      [ 0.0309,  0.0646, -0.0215,  ..., -0.0245, -0.0116, -0.0399],\n",
              "                      ...,\n",
              "                      [ 0.0422, -0.0338, -0.0597,  ..., -0.0148,  0.0315, -0.0308],\n",
              "                      [ 0.0374,  0.0473,  0.0039,  ..., -0.0569, -0.0747,  0.0779],\n",
              "                      [-0.0310, -0.0050, -0.1175,  ..., -0.0504,  0.0680, -0.0278]])),\n",
              "             ('hidden_layers.1.bias',\n",
              "              tensor([ 6.9320e-02,  2.3078e-02,  5.5876e-02, -1.8762e-03,  6.6820e-02,\n",
              "                      -7.1060e-02,  3.9886e-02,  4.5477e-02,  9.6805e-02, -3.0025e-02,\n",
              "                      -1.2057e-02,  4.4022e-02, -3.7991e-02, -3.6140e-02,  5.2874e-02,\n",
              "                       1.2574e-02, -7.6489e-03,  2.7240e-02,  2.8454e-03, -1.8348e-02,\n",
              "                       3.8293e-02,  9.3765e-03,  2.1803e-02,  9.2773e-03, -6.7307e-02,\n",
              "                       5.3817e-02,  7.7273e-02, -2.4375e-02,  9.0084e-02,  1.1273e-01,\n",
              "                       1.9964e-02,  2.4269e-02, -5.0246e-02,  2.1732e-02,  8.2068e-03,\n",
              "                      -7.1961e-02, -1.3427e-02,  1.0009e-01, -1.7397e-02,  3.0233e-03,\n",
              "                      -2.8305e-03,  3.9891e-02, -8.3785e-03,  1.1492e-01, -2.3764e-02,\n",
              "                       2.8473e-02,  4.4161e-02,  8.2886e-02,  7.1889e-02,  1.3683e-03,\n",
              "                       5.6807e-02,  5.2920e-02,  2.9165e-02,  3.1719e-02,  1.6545e-02,\n",
              "                      -5.3610e-02,  3.3565e-02,  9.2863e-03, -3.7095e-02,  4.6009e-02,\n",
              "                       5.2076e-02,  5.4130e-03,  4.4880e-02,  3.9147e-02, -3.0924e-02,\n",
              "                       7.0917e-02,  9.6919e-02, -7.6241e-03, -6.8366e-02,  5.6530e-02,\n",
              "                      -1.9531e-02,  5.5574e-02,  4.5952e-03,  1.8767e-02,  5.1337e-02,\n",
              "                      -4.5561e-02, -6.6299e-03,  6.1755e-02,  2.4667e-02,  1.4114e-02,\n",
              "                       5.2163e-02,  6.7764e-03, -4.7539e-02, -9.9685e-02, -2.3098e-02,\n",
              "                       8.7937e-02,  4.6540e-02,  2.8360e-02, -4.5910e-02, -2.6123e-02,\n",
              "                      -1.7431e-02, -5.8196e-02,  2.3735e-02,  1.4503e-01, -1.1802e-02,\n",
              "                       2.3443e-02,  8.4201e-03,  1.5755e-02,  5.9173e-03,  3.6035e-02,\n",
              "                       9.0268e-02,  2.4974e-02,  6.7387e-02, -8.3149e-03, -8.1609e-03,\n",
              "                      -1.2068e-04, -7.9070e-03, -1.7604e-02, -6.6580e-03, -1.3395e-02,\n",
              "                       7.2334e-02, -7.0322e-03, -6.7581e-02,  1.8580e-02,  8.3128e-02,\n",
              "                      -6.2503e-02,  3.1104e-02,  8.4686e-02, -5.5541e-02, -4.5791e-02,\n",
              "                      -5.2036e-02, -7.6257e-03, -2.5568e-02,  8.1288e-02,  3.1798e-02,\n",
              "                       2.6779e-03, -2.0713e-03,  7.9931e-02,  6.4142e-02,  3.1085e-02,\n",
              "                      -7.0048e-03,  8.1962e-02,  2.1249e-02, -3.9619e-02,  1.4725e-02,\n",
              "                      -2.6987e-02,  1.0125e-01,  1.6252e-02,  3.5196e-02,  1.7346e-02,\n",
              "                       2.3330e-02,  1.5881e-02,  7.3644e-02, -7.3828e-02,  2.5861e-02,\n",
              "                       1.7227e-03, -5.7680e-03, -6.2820e-02,  4.1179e-02, -1.1722e-02,\n",
              "                       3.9737e-02,  4.4946e-02, -4.0340e-02,  2.0600e-02,  2.9407e-02,\n",
              "                      -2.6654e-03, -5.2805e-03,  4.0821e-02, -4.4653e-02,  5.8415e-02,\n",
              "                      -3.1175e-02, -4.6063e-02,  5.0364e-02,  6.0420e-03, -8.1272e-03,\n",
              "                       1.2746e-02, -4.2546e-06, -2.9070e-03,  2.9154e-02,  6.9497e-02,\n",
              "                       1.1711e-02,  3.3540e-02,  9.0079e-02,  3.8359e-02,  3.0210e-02,\n",
              "                       8.9734e-02,  1.6845e-02, -3.7172e-02, -2.0977e-02,  1.6170e-02,\n",
              "                       7.3774e-02,  3.4544e-02,  5.0001e-02,  3.7449e-02, -9.7509e-03,\n",
              "                      -2.9371e-02,  2.1008e-02,  7.3587e-02, -3.4061e-02, -1.7861e-02,\n",
              "                      -5.3223e-02, -4.3889e-02, -4.7297e-02, -8.1016e-03,  1.4522e-02,\n",
              "                       6.1305e-02, -3.8247e-04,  3.6616e-02,  1.3388e-02,  4.4235e-02,\n",
              "                      -3.0074e-02, -7.1206e-02,  1.4885e-02,  3.5388e-02, -2.9064e-02,\n",
              "                       3.0656e-02,  8.7696e-03,  5.1114e-02,  3.8386e-04,  1.5511e-02,\n",
              "                       6.9069e-02,  1.0535e-01, -3.5818e-04, -1.8042e-02,  3.2992e-02,\n",
              "                       1.7473e-02,  3.5575e-02, -2.0283e-03,  5.3611e-02, -8.0873e-03,\n",
              "                      -9.8569e-03, -2.8177e-04,  8.9991e-03,  2.0659e-02,  3.1580e-02,\n",
              "                       3.2633e-02,  1.7909e-03,  5.0608e-02,  3.1649e-02,  4.5269e-02,\n",
              "                      -5.2005e-02,  4.3888e-02,  1.5202e-03,  9.3214e-02, -1.6583e-02,\n",
              "                      -9.4979e-03,  7.7944e-03,  2.9644e-02, -1.3997e-02,  5.7438e-02,\n",
              "                       3.0303e-02,  1.1018e-03, -3.0420e-02,  8.1822e-02, -5.4913e-02,\n",
              "                       2.1555e-02, -2.0828e-02,  1.6232e-02, -3.9306e-02,  1.2247e-01,\n",
              "                      -8.5362e-02, -2.4344e-02,  1.0844e-02,  6.5465e-02,  5.6670e-02,\n",
              "                       4.2156e-02])),\n",
              "             ('hidden_layers.2.weight',\n",
              "              tensor([[-0.0504, -0.0734,  0.0354,  ...,  0.0161,  0.0453,  0.0336],\n",
              "                      [ 0.0684,  0.0438,  0.0310,  ..., -0.0664,  0.0531,  0.0316],\n",
              "                      [-0.0607, -0.0586, -0.0285,  ..., -0.0413, -0.0640, -0.0084],\n",
              "                      ...,\n",
              "                      [ 0.0223, -0.0171, -0.0305,  ...,  0.0529, -0.0276,  0.0557],\n",
              "                      [-0.0129, -0.0414, -0.0654,  ..., -0.0433,  0.0649, -0.0418],\n",
              "                      [-0.0305,  0.0004, -0.0317,  ...,  0.0474,  0.0251,  0.0895]])),\n",
              "             ('hidden_layers.2.bias',\n",
              "              tensor([ 0.1081,  0.0460,  0.0092, -0.0426,  0.0531, -0.0060,  0.0615,  0.0170,\n",
              "                       0.0059, -0.0426,  0.0886,  0.0567,  0.1231,  0.0472,  0.0352,  0.0247,\n",
              "                       0.0803,  0.0618,  0.1014,  0.0294, -0.0244,  0.0078, -0.0027,  0.0174,\n",
              "                       0.0847, -0.0138,  0.1284,  0.1031,  0.0060,  0.1288,  0.0083,  0.0075,\n",
              "                       0.0559,  0.1133, -0.0064,  0.0493,  0.1539,  0.0874,  0.0296,  0.0056,\n",
              "                       0.0742,  0.1370,  0.0736,  0.2301,  0.0142,  0.0983,  0.0204,  0.0090,\n",
              "                       0.0257,  0.0961,  0.0458, -0.0261,  0.1094,  0.1181,  0.1303,  0.0421,\n",
              "                       0.0146,  0.0586,  0.0964,  0.0308, -0.0090,  0.0511,  0.1562,  0.0858,\n",
              "                       0.0391,  0.0514,  0.0486,  0.1064, -0.0655, -0.0054, -0.0627,  0.0059,\n",
              "                       0.0256,  0.2150,  0.0556,  0.1497, -0.0899,  0.0300,  0.0754,  0.0587,\n",
              "                       0.2126,  0.0065,  0.0641,  0.0699,  0.0548,  0.0334, -0.0730,  0.0467,\n",
              "                       0.1129,  0.1210,  0.0655,  0.1138,  0.0784,  0.1314,  0.0183, -0.0299,\n",
              "                       0.0242, -0.0104,  0.0675,  0.0740,  0.1303, -0.0514,  0.0358,  0.0458,\n",
              "                       0.0614,  0.0344,  0.0234,  0.0492,  0.0575,  0.0224,  0.1226,  0.0051,\n",
              "                      -0.0012, -0.0745,  0.0720,  0.0641,  0.0225,  0.0543,  0.1207, -0.0216,\n",
              "                      -0.0121,  0.0702, -0.0238,  0.0088, -0.0380,  0.1548, -0.0082,  0.1030])),\n",
              "             ('output.weight',\n",
              "              tensor([[ 0.0482, -0.0103, -0.0180,  ...,  0.0546, -0.0197,  0.0915],\n",
              "                      [-0.1144,  0.0229,  0.0916,  ..., -0.1318,  0.0299, -0.0775],\n",
              "                      [-0.0485, -0.0069, -0.0991,  ..., -0.0300, -0.0397,  0.0069],\n",
              "                      ...,\n",
              "                      [-0.1102, -0.1517, -0.0069,  ..., -0.1231,  0.0004, -0.0580],\n",
              "                      [-0.0072, -0.0981, -0.0471,  ...,  0.0507,  0.0030, -0.0107],\n",
              "                      [-0.1476, -0.1008,  0.0661,  ..., -0.0680, -0.1166,  0.0127]])),\n",
              "             ('output.bias',\n",
              "              tensor([-0.0994, -0.2291,  0.1609,  0.0642, -0.0256, -0.0077,  0.0788, -0.0565,\n",
              "                       0.0036, -0.1089]))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODnqxVu37rff"
      },
      "source": [
        "* 위 state dictionary를 `torch.save`를 사용하여 저장하면 됩니다\n",
        "* 예를 들어서 이름을 `checkpoint.pth`로 저장하도록 해보죠\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6A0rgL4H7rfg"
      },
      "source": [
        "torch.save(model.state_dict(), 'checkpoint.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAXnJBQo7rfj"
      },
      "source": [
        "* 위 저장된 state dict를 다시  `torch.load`를 통해서 불러올 수 있습니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbPzckIe7rfj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a31e94c5-a702-4882-a24e-71c306475fec"
      },
      "source": [
        "state_dict = torch.load('checkpoint.pth')\n",
        "print(state_dict.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'hidden_layers.2.weight', 'hidden_layers.2.bias', 'output.weight', 'output.bias'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6vPvPS67rfn"
      },
      "source": [
        "* 저장된 state dict를 모델이 적용하기 위해서는 다음과 같은 명령어를 사용합니다\"\n",
        "  * `model.load_state_dict(state_dict)`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzJLRAoM7rfn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9c7b7520-b9f3-4207-a0cd-f7e7e4eb2407"
      },
      "source": [
        "model.load_state_dict(state_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fqd6r3oy7rfs"
      },
      "source": [
        "* 예고한 바와 같이 방법은 간단하죠?\n",
        "* 하지만, 한가지 주의해야할 부분이 있습니다. 쉽게 생각해볼 수 있는데, 내가 저장된 state_dict를 적용하고자 하는 모델과, 저장된 네트워크의 parameter 수 가 맞지 않으면 에러가 납니다 (당연하겠죠?)\n",
        "* 아래 예제를 살펴보죠\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kPErpBl7rft",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "b7c4f2d8-e270-4bdf-ea5d-411e696fbe71"
      },
      "source": [
        "# 저장한 네트워크와 구조를 다르게 새로운 모델을 생성합니다 원 구조는 hidden layer가 [512, 256, 128]였죠?\n",
        "model = fc_model.Network(784, 10, [400, 200, 100])\n",
        "# This will throw an error because the tensor sizes are wrong!\n",
        "model.load_state_dict(state_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-a20171058874>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfc_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# This will throw an error because the tensor sizes are wrong!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 847\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    848\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Network:\n\tsize mismatch for hidden_layers.0.weight: copying a param with shape torch.Size([512, 784]) from checkpoint, the shape in current model is torch.Size([400, 784]).\n\tsize mismatch for hidden_layers.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([400]).\n\tsize mismatch for hidden_layers.1.weight: copying a param with shape torch.Size([256, 512]) from checkpoint, the shape in current model is torch.Size([200, 400]).\n\tsize mismatch for hidden_layers.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([200]).\n\tsize mismatch for hidden_layers.2.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([100, 200]).\n\tsize mismatch for hidden_layers.2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([100]).\n\tsize mismatch for output.weight: copying a param with shape torch.Size([10, 128]) from checkpoint, the shape in current model is torch.Size([10, 100])."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "is9yRa-O7rfv"
      },
      "source": [
        "### 네트워크 구조를 함께 저장하기\n",
        "* 요약하자면, 적용하고자하는 state_dict의 구조에 정확히 맞춰서 적용해야 한다는 뜻입니다\n",
        "* 그렇다면, 저장하고자하는 네트워크의 구조도 함께 저장해두면 편리하겠죠?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5fL8n5a7rfw"
      },
      "source": [
        "checkpoint = {'input_size': 784,\n",
        "              'output_size': 10,\n",
        "              'hidden_layers': [each.out_features for each in model.hidden_layers],\n",
        "              'state_dict': model.state_dict()}\n",
        "\n",
        "torch.save(checkpoint, 'checkpoint.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8ADf4sD7rf0"
      },
      "source": [
        "* 이제 원하는 모든 정보를 저장하였습니다\n",
        "* 불러오기를 쉽게 하기 위해서, 저장 구조를 이해하고 불러오기 모듈을 작성해봅니다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQ3dP-t27rf0"
      },
      "source": [
        "## Exercise 1\n",
        "아래 `load_checkpoint` 모듈을 완성하세요\n",
        "  * 위에서 저장한 checkpoint dictionary를 `checkpoint`로 불러옵니다\n",
        "  * 위에서 저장한 구조 정보를 활용하여 `model`을 완성하세요\n",
        "  * `load_state_dict`를 사용하여 생성한 `model`에 training 된 parameter를 적용하세요"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppo_5nJx7rf1"
      },
      "source": [
        "def load_checkpoint(filepath):\n",
        "    ############## 답 작성 ##############\n",
        "\n",
        "    checkpoint = torch.load(filepath) # 파일을 불러옴\n",
        "    model = fc_model.Network(checkpoint['input_size'], \n",
        "                             checkpoint['output_size'],\n",
        "                             checkpoint['hidden_layers'])\n",
        "    #checkpoint 딕셔너리의 input_size, output_size, hidden_layers를 fc_model.Network에 넣음\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    # checkpoint 자료구조의 state_dict를 불러서 load해서 state_dict에 load를 함\n",
        "    #####################################\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pamf60J7rf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "48d803ed-ebd6-4e42-e890-959351206092"
      },
      "source": [
        "model = load_checkpoint('checkpoint.pth')\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Network(\n",
            "  (hidden_layers): ModuleList(\n",
            "    (0): Linear(in_features=784, out_features=400, bias=True)\n",
            "    (1): Linear(in_features=400, out_features=200, bias=True)\n",
            "    (2): Linear(in_features=200, out_features=100, bias=True)\n",
            "  )\n",
            "  (output): Linear(in_features=100, out_features=10, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHoUQva97rf7"
      },
      "source": [
        "# Part 2: Transfer Learning\n",
        "\n",
        "* Part 2에서는 이미 training이 잘된 네트워크를 불러와서 적용하는 방법을 실습하도록 하겠습니다\n",
        "* '잘된 네트워크'는 여기서 [ImageNet](http://www.image-net.org/) [available from torchvision](http://pytorch.org/docs/0.3.0/torchvision/models.html)에서 학습된 모델을 활용하도록 하겠습니다\n",
        "* `ImageNet`은 14,000,000개의 image파일을 20,000개의 class로 분류되어있는 database 운영\n",
        "  * 예를 들면 `딸기`, `풍선`등의 분류가 있으면, 각 분류별로 수백개의 image가 존재합니다\n",
        "  * 각 이미지들은 수작업으로 labeling 되어있고, bounding box까지 표시가 되어 있습니다\n",
        "  * 2010년 이후로 대회를 진행 ImageNet Large Scale Visual Recognition Challenge (ILSVRC)\n",
        "    * 수천개의 class를 추려서 대회 진행\n",
        "  * AlexNet과 그 이후: top-5 분류에서 15.3%로 혁신적 결과를 시작으로 deep learning 시대를 견인\n",
        "    * GPU의 사용!\n",
        "* 우리는 실제 사용하고자 하는 network를 직접 training 하는 경우보다, imagenet 등에서 매우 잘 동작하는 network을 적용하여, 부분적 학습을 통해서 사용하게 됩니다\n",
        "* 본 실습에서는 imagenet에서 모델을 받아서 적용하는 방법을 알아보죠~\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxsVLa9s7rf8"
      },
      "source": [
        "### Data 준비\n",
        "* 위 Imagenet에서 사용된 자료는 다양한 class를 분류하는 작업을 수행합니다\n",
        "* 이를 우리가 지난 시간에 받았던 `dog`, `cat`분류 문제에 적용하는 방법을 알아보도록 하겠습니다\n",
        "* 자료 받은 것이 있다면, 본 경로에 복사하여 사용하거나, 아래 셀을 실행하여 자료를 받습니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKZgDLH_7rf8"
      },
      "source": [
        "from os.path import exists\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "import tarfile \n",
        "\n",
        " \n",
        "gdd.download_file_from_google_drive(file_id='1Glpk4kdbrs_mXJX8Nl71Mw4SfaFsl45u',\n",
        "                                   dest_path = './Cat_Dog_data.tgz')\n",
        "\n",
        "tf = tarfile.open(\"Cat_Dog_data.tgz\")\n",
        "tf.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6ZIPUKC7rf_"
      },
      "source": [
        "### Loading Densenet121\n",
        "* 본 실습을 위해서 우리는 [DenseNet](http://pytorch.org/docs/0.3.0/torchvision/models.html#id5)을 활용하고자 합니다. 아래 불러오기와 구조를 살펴보죠"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAIrW2EY7rgA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7af27287-b010-42f6-db15-36598bc24dc2"
      },
      "source": [
        "from torchvision import models\n",
        "model = models.densenet121(pretrained=True)\n",
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DenseNet(\n",
              "  (features): Sequential(\n",
              "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu0): ReLU(inplace=True)\n",
              "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (denseblock1): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (transition1): _Transition(\n",
              "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (denseblock2): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer7): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer8): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer9): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer10): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer11): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer12): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (transition2): _Transition(\n",
              "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (denseblock3): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer7): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer8): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer9): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer10): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer11): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer12): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer13): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer14): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer15): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer16): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer17): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer18): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer19): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer20): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer21): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer22): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer23): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer24): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (transition3): _Transition(\n",
              "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (denseblock4): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer7): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer8): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer9): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer10): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer11): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer12): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer13): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer14): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer15): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer16): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (classifier): Linear(in_features=1024, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZpaSNzP7rgD"
      },
      "source": [
        "### densenet121의 구조\n",
        "\n",
        "* 위에서 불러온 `densenet121`의 구조를 살펴보면 크게 두가지로 나눠집니다\n",
        "  * (features) 부분과\n",
        "  * (classifier) 부분으로 나눠집니다\n",
        "* 위에서 (features) 부분은 매우 복잡한 layer들로 구성되어 있으며, 특별히, convolutional network으로 구성되어 있습니다. (이부분은 다음 시간부터 배우게 됩니다)\n",
        "* 여기서 (features)에 해당하는 부분은 그대로 활용할 것이며, classifier에 대당하는 부분만 바꿔서 사용하고자 합니다\n",
        "* 여기서 유념해야하는 부분은 classifier의 `output_feature=1000` 부분입니다\n",
        "  * (classifier)는 fully-connected layer로\n",
        "    * `(classifier): Linear(in_features=1024, out_features=1000)` 임\n",
        "  * `output_feature=1000`는 분류는 1000가지로 수행하고 있는 네트워크라는 뜻입니다\n",
        "  * 우리는 이부분을 2가지 dog, cat 중 한가지로 수행하도록 변경하고자 합니다\n",
        "  \n",
        "* 또한, densenet121은 입력 image가 224x224로 받습니다\n",
        "* Densenet121에서 정규화한 값 또한 맞춰줘야 합니다 Densenet121의 경우는 \n",
        "  * mean `[0.485, 0.456, 0.406]` and the standard deviations `[0.229, 0.224, 0.225]`로 학습되었습니다\n",
        "* 위 정보에 맞춰서 우리 학습하고자 하는 IMAGE를 불러옵니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVCoDAL07rgD"
      },
      "source": [
        "data_dir = 'Cat_Dog_data'\n",
        "\n",
        "# TODO: Define transforms for the training data and testing data\n",
        "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
        "                                       transforms.RandomResizedCrop(224),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                            [0.229, 0.224, 0.225])])\n",
        "\n",
        "test_transforms = transforms.Compose([transforms.Resize(255),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                           [0.229, 0.224, 0.225])])\n",
        "\n",
        "# Pass transforms in here, then run the next cell to see how the transforms look\n",
        "train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n",
        "test_data = datasets.ImageFolder(data_dir + '/test', transform=test_transforms)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(test_data, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TuzMBky7rgG"
      },
      "source": [
        "## Transfer learning\n",
        "\n",
        "* 위에서 가져온 densenet121의 네트워크에서 우리는 `classifier` 부분을 다시 우리 목적에 맞게 설계하고 다시 학습하고자 합니다 (이유는 영상에서 설명하도록 하겠습니다)\n",
        "\n",
        "* 이때, densenet121에서 `feature` 부분은 다시 training 하지 않고 그대로 유지합니다. 이를 위해서 `feature`부분은 동결 (freeze)하고, 즉 backprop을 수행하지 않고, `classifier`부분만 수행합니다.\n",
        "\n",
        "* 동결을 위해서 모든 `model.paramters()`의 `requires_grad = False` 로 바꿔줍니다\n",
        "* 이후 classifier 부분을 덮어서 새로 구현하면, 이부분은 자동으로 gradient가 활성화 된 상태로 만들어지겠죠?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oh3zD3Iz7rgG"
      },
      "source": [
        "# Backprop을 수행하지 않도록 parameter들을 동결시킴\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "from collections import OrderedDict\n",
        "classifier = nn.Sequential(OrderedDict([\n",
        "                          ('fc1', nn.Linear(1024, 500)),\n",
        "                          ('relu', nn.ReLU()),\n",
        "                          ('fc2', nn.Linear(500, 2)),\n",
        "                          ('output', nn.LogSoftmax(dim=1))\n",
        "                          ]))\n",
        "    \n",
        "model.classifier = classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNtY9U5Z7rgK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eefdd6e5-68d6-4e30-fad7-5bcf1b3671dd"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DenseNet(\n",
              "  (features): Sequential(\n",
              "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu0): ReLU(inplace=True)\n",
              "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (denseblock1): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (transition1): _Transition(\n",
              "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (denseblock2): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer7): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer8): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer9): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer10): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer11): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer12): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (transition2): _Transition(\n",
              "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (denseblock3): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer7): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer8): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer9): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer10): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer11): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer12): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer13): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer14): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer15): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer16): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer17): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer18): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer19): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer20): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer21): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer22): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer23): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer24): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (transition3): _Transition(\n",
              "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (denseblock4): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer7): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer8): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer9): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer10): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer11): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer12): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer13): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer14): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer15): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer16): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
              "    (relu): ReLU()\n",
              "    (fc2): Linear(in_features=500, out_features=2, bias=True)\n",
              "    (output): LogSoftmax()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTJCiDRi7rgM"
      },
      "source": [
        "## Cuda (GPU활용)\n",
        "\n",
        "* dense121 처럼 좋은 성능의 네트워크는 많은 연산량을 요구하여 연산량이 많습니다\n",
        "* 이를 가속화하기 위해서 pytorch는 GPU로 연산하는 방법을 제공합니다\n",
        "* GPU에서 연산을 수행하면, CPU를 활용하는 것 보다 100배 이상 빠른 속도를 제공합니다\n",
        "* 본 실습 docker 환경 및 nvidia gpu가 없는 경우는 GPU를 통한 연산 지원이 되지 않습니다\n",
        "* 앞으로 실습에서 GPU를 활용하는 환경을 cloud에서 수행하는 방법을 설명하겠습니다\n",
        "* 아래에서는 본 학습 영상을 위한 부분이니, 주석처리하시면 됩니다 (영상에서 효과 보시면 됩니다)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7xekDl57rgN"
      },
      "source": [
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eli_uyQu7rgP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "75d6d7eb-fc1b-462c-a2f5-30876ef0bfc4"
      },
      "source": [
        "for device in ['cpu', 'cuda']:\n",
        "\n",
        "    criterion = nn.NLLLoss()\n",
        "    # Only train the classifier parameters, feature parameters are frozen\n",
        "    optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    for ii, (inputs, labels) in enumerate(trainloader):\n",
        "\n",
        "        # Move input and label tensors to the GPU\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        start = time.time()\n",
        "\n",
        "        outputs = model.forward(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if ii==3:\n",
        "            break\n",
        "        \n",
        "    print(f\"Device = {device}; Time per batch: {(time.time() - start)/3:.3f} seconds\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device = cpu; Time per batch: 3.938 seconds\n",
            "Device = cuda; Time per batch: 0.008 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjGUPAXI7rgR"
      },
      "source": [
        "## GPU 활용법\n",
        "\n",
        "일반적으로 gpu를 활용하는 좋은 방법은 아래와 같은 줄을 추가하여 GPU가 있는 경우와 없는 경우를 분류합니다\n",
        "\n",
        "```python\n",
        "# at beginning of the script\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "...\n",
        "\n",
        "# 이후 tensor나 모듈을 선언할때, 아래와 같이 수행합니다\n",
        "input = data.to(device)\n",
        "model = MyModule(...).to(device)\n",
        "```\n",
        "\n",
        "나머지 training 하는 방법은 기존과 똑같은 과정을 통해서 할 수 있습니다. 아래 실습을 해보죠.\n",
        "\n",
        ">**Exercise 2:** \n",
        "cat, dog image를 transfer learning한 위 network를 활용하여 학습하세요. 가능하신 분들은 resnet을 통해서 학습을 수행해보세요. GPU가 없기 때문에 GPU학습은 불가하지만, 위 \n",
        "`device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")`\n",
        "를 사용하여 gpu가 있다면, gpu 학습이 가능하도록 코드를 추가하세요.\n",
        "\n",
        "* 최종적으로 다음과 같이 출력되도록 validation과 training을 수행하시면 됩니다 (지난 수업 참고)\n",
        "```\n",
        "Epoch 1/1.. Train loss: 0.835.. Test loss: 0.344.. Test accuracy: 0.841\n",
        "Epoch 1/1.. Train loss: 0.480.. Test loss: 0.131.. Test accuracy: 0.966\n",
        "Epoch 1/1.. Train loss: 0.361.. Test loss: 0.112.. Test accuracy: 0.969\n",
        "Epoch 1/1.. Train loss: 0.225.. Test loss: 0.087.. Test accuracy: 0.974\n",
        "Epoch 1/1.. Train loss: 0.222.. Test loss: 0.117.. Test accuracy: 0.955\n",
        "Epoch 1/1.. Train loss: 0.231.. Test loss: 0.077.. Test accuracy: 0.973\n",
        "Epoch 1/1.. Train loss: 0.196.. Test loss: 0.084.. Test accuracy: 0.968\n",
        "Epoch 1/1.. Train loss: 0.180.. Test loss: 0.058.. Test accuracy: 0.979\n",
        "Epoch 1/1.. Train loss: 0.184.. Test loss: 0.066.. Test accuracy: 0.975\n",
        "Epoch 1/1.. Train loss: 0.149.. Test loss: 0.063.. Test accuracy: 0.979\n",
        "Epoch 1/1.. Train loss: 0.204.. Test loss: 0.059.. Test accuracy: 0.977\n",
        "Epoch 1/1.. Train loss: 0.193.. Test loss: 0.053.. Test accuracy: 0.982\n",
        "Epoch 1/1.. Train loss: 0.138.. Test loss: 0.057.. Test accuracy: 0.980\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeCLhSbj7rgT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d8574657-7192-4a0f-8964-d24bc80dce1f"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC9KQJsm7rgW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ee5c629d-f213-4643-f221-d95ccd3ad8dd"
      },
      "source": [
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8bmLWSFbLEw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b41b295f-2af9-445a-b21e-91f9c16f4cf9"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJ50MFFG7rgZ",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1997b9f7-3a8f-4a51-b7b4-e3d0cc040bb8"
      },
      "source": [
        "################## 답 작성\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = models.densenet121(pretrained=True)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False # gradient 모두 끔\n",
        "\n",
        "model.classifier = nn.Sequential(nn.Linear(1024,256),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.Dropout(0.2),\n",
        "                                 nn.Linear(256,2),\n",
        "                                 nn.LogSoftmax(dim=1))\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(model.classifier.parameters(), lr=0.003)\n",
        "\n",
        "model.to(device);\n",
        "\n",
        "epochs = 1\n",
        "steps = 0\n",
        "running_loss = 0\n",
        "print_every = 5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for inputs, labels in trainloader:\n",
        "        steps += 1\n",
        "\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        logps = model.forward(inputs)\n",
        "        loss = criterion(logps, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if steps % print_every == 0:\n",
        "            test_loss = 0\n",
        "            accuracy = 0\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                for inputs, labels in testloader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    logps = model.forward(inputs)\n",
        "                    batch_loss = criterion(logps, labels)\n",
        "\n",
        "                    test_loss += batch_loss.item()\n",
        "\n",
        "                    #Calculate accuracy\n",
        "                    ps = torch.exp(logps)\n",
        "                    top_p, top_class = ps.topk(1, dim=1)\n",
        "                    equals = top_class == labels.view(*top_class.shape)\n",
        "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "\n",
        "            print(f\"Epoch {epoch+1}/{epoch}..\"\n",
        "                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
        "                  f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
        "                  f\"Teest accuracy: {accuracy/len(testloader):.3f}\")\n",
        "            running_loss = 0\n",
        "            model.train()\n",
        "\n",
        "########################################################"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/0..Train loss: 0.447.. Test loss: 0.090.. Teest accuracy: 0.966\n",
            "Epoch 1/0..Train loss: 0.423.. Test loss: 0.166.. Teest accuracy: 0.941\n",
            "Epoch 1/0..Train loss: 0.352.. Test loss: 0.127.. Teest accuracy: 0.949\n",
            "Epoch 1/0..Train loss: 0.265.. Test loss: 0.067.. Teest accuracy: 0.975\n",
            "Epoch 1/0..Train loss: 0.326.. Test loss: 0.051.. Teest accuracy: 0.982\n",
            "Epoch 1/0..Train loss: 0.383.. Test loss: 0.092.. Teest accuracy: 0.962\n",
            "Epoch 1/0..Train loss: 0.223.. Test loss: 0.081.. Teest accuracy: 0.976\n",
            "Epoch 1/0..Train loss: 0.288.. Test loss: 0.090.. Teest accuracy: 0.963\n",
            "Epoch 1/0..Train loss: 0.230.. Test loss: 0.088.. Teest accuracy: 0.973\n",
            "Epoch 1/0..Train loss: 0.197.. Test loss: 0.063.. Teest accuracy: 0.975\n",
            "Epoch 1/0..Train loss: 0.190.. Test loss: 0.054.. Teest accuracy: 0.979\n",
            "Epoch 1/0..Train loss: 0.198.. Test loss: 0.055.. Teest accuracy: 0.982\n",
            "Epoch 1/0..Train loss: 0.173.. Test loss: 0.064.. Teest accuracy: 0.975\n",
            "Epoch 1/0..Train loss: 0.138.. Test loss: 0.047.. Teest accuracy: 0.984\n",
            "Epoch 1/0..Train loss: 0.138.. Test loss: 0.048.. Teest accuracy: 0.981\n",
            "Epoch 1/0..Train loss: 0.209.. Test loss: 0.052.. Teest accuracy: 0.980\n",
            "Epoch 1/0..Train loss: 0.169.. Test loss: 0.048.. Teest accuracy: 0.982\n",
            "Epoch 1/0..Train loss: 0.162.. Test loss: 0.048.. Teest accuracy: 0.982\n",
            "Epoch 1/0..Train loss: 0.160.. Test loss: 0.047.. Teest accuracy: 0.982\n",
            "Epoch 1/0..Train loss: 0.157.. Test loss: 0.044.. Teest accuracy: 0.982\n",
            "Epoch 1/0..Train loss: 0.150.. Test loss: 0.044.. Teest accuracy: 0.982\n",
            "Epoch 1/0..Train loss: 0.159.. Test loss: 0.043.. Teest accuracy: 0.982\n",
            "Epoch 1/0..Train loss: 0.178.. Test loss: 0.043.. Teest accuracy: 0.984\n",
            "Epoch 1/0..Train loss: 0.183.. Test loss: 0.046.. Teest accuracy: 0.984\n",
            "Epoch 1/0..Train loss: 0.171.. Test loss: 0.048.. Teest accuracy: 0.983\n",
            "Epoch 1/0..Train loss: 0.125.. Test loss: 0.053.. Teest accuracy: 0.983\n",
            "Epoch 1/0..Train loss: 0.169.. Test loss: 0.043.. Teest accuracy: 0.982\n",
            "Epoch 1/0..Train loss: 0.144.. Test loss: 0.043.. Teest accuracy: 0.985\n",
            "Epoch 1/0..Train loss: 0.149.. Test loss: 0.042.. Teest accuracy: 0.984\n",
            "Epoch 1/0..Train loss: 0.136.. Test loss: 0.052.. Teest accuracy: 0.982\n",
            "Epoch 1/0..Train loss: 0.154.. Test loss: 0.053.. Teest accuracy: 0.980\n",
            "Epoch 1/0..Train loss: 0.137.. Test loss: 0.051.. Teest accuracy: 0.982\n",
            "Epoch 1/0..Train loss: 0.125.. Test loss: 0.047.. Teest accuracy: 0.981\n",
            "Epoch 1/0..Train loss: 0.222.. Test loss: 0.041.. Teest accuracy: 0.984\n",
            "Epoch 1/0..Train loss: 0.207.. Test loss: 0.041.. Teest accuracy: 0.983\n",
            "Epoch 1/0..Train loss: 0.172.. Test loss: 0.043.. Teest accuracy: 0.984\n",
            "Epoch 1/0..Train loss: 0.141.. Test loss: 0.042.. Teest accuracy: 0.984\n",
            "Epoch 1/0..Train loss: 0.158.. Test loss: 0.045.. Teest accuracy: 0.984\n",
            "Epoch 1/0..Train loss: 0.144.. Test loss: 0.042.. Teest accuracy: 0.984\n",
            "Epoch 1/0..Train loss: 0.200.. Test loss: 0.046.. Teest accuracy: 0.983\n",
            "Epoch 1/0..Train loss: 0.157.. Test loss: 0.042.. Teest accuracy: 0.984\n",
            "Epoch 1/0..Train loss: 0.119.. Test loss: 0.042.. Teest accuracy: 0.985\n",
            "Epoch 1/0..Train loss: 0.136.. Test loss: 0.047.. Teest accuracy: 0.980\n",
            "Epoch 1/0..Train loss: 0.141.. Test loss: 0.041.. Teest accuracy: 0.985\n",
            "Epoch 1/0..Train loss: 0.169.. Test loss: 0.043.. Teest accuracy: 0.984\n",
            "Epoch 1/0..Train loss: 0.137.. Test loss: 0.041.. Teest accuracy: 0.986\n",
            "Epoch 1/0..Train loss: 0.174.. Test loss: 0.045.. Teest accuracy: 0.982\n",
            "Epoch 1/0..Train loss: 0.176.. Test loss: 0.053.. Teest accuracy: 0.982\n",
            "Epoch 1/0..Train loss: 0.126.. Test loss: 0.043.. Teest accuracy: 0.984\n",
            "Epoch 1/0..Train loss: 0.147.. Test loss: 0.040.. Teest accuracy: 0.986\n",
            "Epoch 1/0..Train loss: 0.112.. Test loss: 0.038.. Teest accuracy: 0.985\n",
            "Epoch 1/0..Train loss: 0.148.. Test loss: 0.041.. Teest accuracy: 0.987\n",
            "Epoch 1/0..Train loss: 0.130.. Test loss: 0.038.. Teest accuracy: 0.986\n",
            "Epoch 1/0..Train loss: 0.133.. Test loss: 0.039.. Teest accuracy: 0.986\n",
            "Epoch 1/0..Train loss: 0.118.. Test loss: 0.039.. Teest accuracy: 0.985\n",
            "Epoch 1/0..Train loss: 0.187.. Test loss: 0.054.. Teest accuracy: 0.976\n",
            "Epoch 1/0..Train loss: 0.151.. Test loss: 0.065.. Teest accuracy: 0.978\n",
            "Epoch 1/0..Train loss: 0.194.. Test loss: 0.050.. Teest accuracy: 0.979\n",
            "Epoch 1/0..Train loss: 0.210.. Test loss: 0.044.. Teest accuracy: 0.986\n",
            "Epoch 1/0..Train loss: 0.182.. Test loss: 0.044.. Teest accuracy: 0.986\n",
            "Epoch 1/0..Train loss: 0.106.. Test loss: 0.074.. Teest accuracy: 0.971\n",
            "Epoch 1/0..Train loss: 0.189.. Test loss: 0.046.. Teest accuracy: 0.985\n",
            "Epoch 1/0..Train loss: 0.205.. Test loss: 0.041.. Teest accuracy: 0.983\n",
            "Epoch 1/0..Train loss: 0.133.. Test loss: 0.053.. Teest accuracy: 0.979\n",
            "Epoch 1/0..Train loss: 0.124.. Test loss: 0.046.. Teest accuracy: 0.987\n",
            "Epoch 1/0..Train loss: 0.212.. Test loss: 0.051.. Teest accuracy: 0.983\n",
            "Epoch 1/0..Train loss: 0.149.. Test loss: 0.078.. Teest accuracy: 0.969\n",
            "Epoch 1/0..Train loss: 0.163.. Test loss: 0.041.. Teest accuracy: 0.983\n",
            "Epoch 1/0..Train loss: 0.158.. Test loss: 0.040.. Teest accuracy: 0.985\n",
            "Epoch 1/0..Train loss: 0.114.. Test loss: 0.040.. Teest accuracy: 0.984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rImVKVXxpw54"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}