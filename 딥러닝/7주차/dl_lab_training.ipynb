{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "20145128_박인근_7주차.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-sV78d192v7"
      },
      "source": [
        "# Training Neural Networks\n",
        "\n",
        "* 이전 시간까지 만들었던 neural network은 똑똑하지는 않았죠 (training을 하지 않아 손글씨를 분류하지 못했습니다)\n",
        "* 궁극적으로 neural network은 다양한 function으로 fitting 될 수 있는 universal function approximator가 될 수 있습니다\n",
        "\n",
        "* 즉 training을 잘 거친 neural network은 손글씨 image를 분류하는 분류 function으로 변신이 가능한 것이죠\n",
        "* 더욱이, 낮은 복잡도 내에서 수행 가능합니다\n",
        "<img src=\"assets/function_approx.png\" width=500px>\n",
        "\n",
        "* 수업에서 배운 것과 같이, 좋은 parameter를 찾는 과정을 위해서 *성능*을 측정할 수 있는 측도, 즉 **loss function**이 필요합니다\n",
        "* 예를 들어서 mean squared loss 는 regression 문제와 binary classification 문제에 적용 가능합니다 (classification을 위해서는 더 좋은 loss function이 존재합니다)\n",
        "\n",
        "$$\n",
        "\\large \\ell = \\frac{1}{2n}\\sum_i^n{\\left(y_i - \\hat{y}_i\\right)^2}\n",
        "$$\n",
        "\n",
        "* 위 수식에서 $n$은 training sample의 수, $y_i$는 true labels, $\\hat{y}_i$은 예측입니다\n",
        "\n",
        "* 위 loss function을 network parmeter에 대해서 최소화하는 것이 *학습* 이죠\n",
        "* 최소 값을 찾는 과정은 **gradient descent**를 사용합니다\n",
        "* Gradient descent는 loss function의 기울기를 정보를 활용하여 최소값을 찾아가는 과정이죠 (이론강의 참고)\n",
        "\n",
        "<img src='assets/gradient_descent.png' width=350px>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylWBaFAI92v_"
      },
      "source": [
        "## Loss Functions in PyTorch\n",
        "\n",
        "* 다음 과정으로, Pytorch에서 loss를 어떻게 연산하는지 배워보죠\n",
        "* `nn` module에서 다양한 loss function을 제공하는데, 예를 들면 `nn.CrossEntropyLoss`와 같은 함수가 있습니다\n",
        "    * 보통 관습적으로 loss function은 `critertion`이라는 변수로 받습니다 (`loss_function`등도 당연히 사용 가능합니다)\n",
        "* 지난 시간에 MNIST 문제는 확률 분포를 output으로 받는 것이 필요하다고 (또는 자연스러운 선택 임을) 학습했습니다 \n",
        "* 이런 확률 분포를 output으로 받는 경우 대응되는 좋은 loss function이 cross entropy입니다 (이론 강의에서 cross entropy가 무엇을 의미하는지 설명한 부분을 복습 해보세요)\n",
        "\n",
        "* Cross entropy의 정의는 \n",
        "\\begin{align*}\n",
        " H(P, Q) &= -\\mathbb{E}_{y\\sim P} \\log(Q(y)) \\\\\n",
        " &=-\\sum_{y\\in\\mathcal{Y}} P(y)\\log(Q(y))\n",
        "\\end{align*}\n",
        "* 위 식은 두 확률 분포의 \"거리\"를 표현하는 식이라고 배웠습니다\n",
        "* 위에서 $P(x)$는 $x$의 label을 one hot coding 한 vector이고 $Q(x)$는 softmax를 취한 network output입니다\n",
        "* One hot coding은 y label이 1이면 첫번째 자리만 '1'이고 나머지는 영인 벡터, y label이 $k$이면 $k$ 번째 자리만 '1'이고 나머지는 0인 벡터입니다\n",
        "\n",
        "* 예를들어서 y=2에 대한 one hot encoding\n",
        "\\begin{align*}\n",
        "y_\\textrm{one_hot}(2) &= \\begin{array}{cccccc}\n",
        "[0 & 1 & 0 & \\cdots & 0]\n",
        "\\end{array}\n",
        "\\end{align*}\n",
        "\n",
        "* 위 cross entropy 식에 대응 하는 방식은:\n",
        "\\begin{align*}\n",
        "P(y=2) = y_\\textrm{one_hot}(2)\n",
        "\\end{align*}\n",
        "\n",
        "* 또한, neural network의 마지막 linear layer의 output 값이 $z$라고 할때,\n",
        "\\begin{align*}\n",
        "Q(y=2) = \\sigma(z_2) = \\cfrac{\\exp(z_2)}{\\sum_k^K{\\exp(z_k)}}\n",
        "\\end{align*}\n",
        "\n",
        "<img src='assets/NLLLoss.jpg' width=550px>\n",
        "\n",
        "* pytorch에서 이를 수행하기 위해서 criterion을 `nn.CrossEntropyLoss`로 생성하고, network의 예측 값과, 실제 label 값을 입력으로 loss를 계산합니다\n",
        "  * 본 과정은 차근차근 설명하겠습니다\n",
        "* 그 전에 Pytorch에서 cross entropy 함수를 어떻게 적용하는지 먼저 이해할 필요가 있습니다 (중요합니다!!!)\n",
        "  * [Pytorch.org `nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss)를 살펴보면\n",
        "\n",
        "> This criterion combines nn.LogSoftmax() and nn.NLLLoss() in one single class.\n",
        ">\n",
        "> The input is expected to contain scores for each class.\n",
        "\n",
        "* `nn.CrossEntropyLoss`는 `nn.LogSoftmax()`와 `nn.NLLLoss()` 하나의 class에서 수행한다고 되어 있습니다. \n",
        "* 두번째 줄에서 NLLLoss 는 negative log likelihood loss 입니다 \n",
        "\n",
        "* 이게 의미하는 바가 무엇이냐면, network의 output을 softmax function을 적용하여 출력하지 말고, softmax는 loss function에서 계산한다는 뜻입니다\n",
        "* 이렇게 구현한 이유는, 확률값이 작을 수 있어서 computation precision error를 방지하기 위해서 그냥 raw output 값을 받고, loss function에서 log(prob) 형태로 연산하도록 모듈을 구성하였습니다\n",
        "\n",
        "* 아래 코드를 보면 조금 더 이해가 될 것이라고 생각합니다\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVYqVs2492wA"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,)),\n",
        "                              ])\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-CkVDCE92wB",
        "outputId": "f063cd56-6995-4107-c228-64937144f676"
      },
      "source": [
        "# Build a feed-forward network\n",
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10))\n",
        "\n",
        "# Define the loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Get our data\n",
        "images, labels = next(iter(trainloader))\n",
        "\n",
        "# Flatten images\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "# Forward pass, get our logits\n",
        "logits = model(images)\n",
        "# Calculate the loss with the logits and the labels\n",
        "loss = criterion(logits, labels)\n",
        "\n",
        "print(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.2832, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWgoAh_P92wD"
      },
      "source": [
        "* 주어진 CrossEntropyLoss()를 사용하지 않고, 조금 더 구체적으로 직접 cross entropy loss를 구현할 수 있습니다\n",
        "* 예를 들어서 output에 log-softmax activation function을 적용하면: `nn.LogSoftmax` 또는 `F.log_softmax` ([자료](https://pytorch.org/docs/stable/nn.html#torch.nn.LogSoftmax))\n",
        "  * 이점은 나중에 확률 값을 간단히 `torch.exp(output)`를 통해서 얻을 수 있습니다\n",
        "* 최종적으로 Cross entropy를 구하기 위해서는 log-softmax output에, loss function을 `nn.NLLLoss` ([자료](https://pytorch.org/docs/stable/nn.html#torch.nn.NLLLoss))로 정의하면 같은 효과입니다\n",
        "* Pytorch에서 NLLLoss 함수는 log probability를 입력으로 받음 \n",
        "  \n",
        "\n",
        ">**Exercise 1[5 points]:** \n",
        "* 위와 같은 네트워크에 마지막 layer을 LogSoftmax를 적용하고 (dim 옵션 필요)\n",
        "* `criterion`을 `nn.NLLLoss()`로 적용하는 네트워크를 구성하세요\n",
        "* output layer에 LogSoftmax를 적용하여 출력하고, NLLLoss를 loss function으로 활용합니다 \n",
        "\n",
        "`output`\n",
        "```python \n",
        "tensor(2.3445, grad_fn=<NllLossBackward>)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFrwzHOl92wE",
        "outputId": "5a11f27a-0f01-4959-d829-1f1d8718b6fe"
      },
      "source": [
        "## Solution\n",
        "\n",
        "# Build a feed-forward network\n",
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1)) # CrossEntropyLoss()를 사용하지 않기 때문에 네트워크 내에서 LogSoftmax(dim=1)을 취해줌\n",
        "\n",
        "# Define the loss\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "# Get our data\n",
        "images, labels = next(iter(trainloader))\n",
        "\n",
        "# Flatten images\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "# Forward pass, get our log-probabilities\n",
        "logps = model(images)\n",
        "# Calculate the loss with the logps and the labels\n",
        "loss = criterion(logps, labels)\n",
        "\n",
        "print(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.2857, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nSf7DIU92wE",
        "outputId": "bf097451-ceee-40f7-cfee-507b8deb078c"
      },
      "source": [
        "labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([9, 1, 0, 8, 4, 2, 5, 9, 6, 8, 4, 2, 4, 7, 4, 2, 8, 6, 9, 3, 9, 5, 5, 6,\n",
              "        7, 6, 7, 7, 6, 5, 3, 8, 6, 9, 5, 8, 8, 0, 3, 6, 8, 0, 8, 8, 6, 5, 4, 7,\n",
              "        4, 9, 3, 9, 4, 1, 3, 1, 1, 7, 7, 7, 9, 2, 8, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsApbaBw92wF",
        "outputId": "2914e79f-cd11-4828-d70b-0de7ed4ed199"
      },
      "source": [
        "logps"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.1617, -2.3311, -2.3795, -2.2732, -2.1263, -2.3657, -2.3374, -2.3666,\n",
              "         -2.4385, -2.2898],\n",
              "        [-2.1562, -2.3473, -2.3481, -2.2698, -2.1151, -2.3567, -2.4065, -2.3688,\n",
              "         -2.4357, -2.2720],\n",
              "        [-2.0200, -2.3650, -2.4431, -2.3010, -2.1445, -2.3713, -2.4618, -2.3585,\n",
              "         -2.4463, -2.2127],\n",
              "        [-2.1557, -2.3503, -2.4266, -2.2244, -2.1166, -2.2552, -2.4179, -2.3903,\n",
              "         -2.4388, -2.3117],\n",
              "        [-2.0934, -2.3344, -2.3761, -2.3104, -2.1239, -2.3177, -2.4159, -2.3727,\n",
              "         -2.4560, -2.2891],\n",
              "        [-2.0820, -2.4092, -2.3733, -2.2709, -2.0652, -2.2651, -2.4495, -2.4350,\n",
              "         -2.4850, -2.2909],\n",
              "        [-2.1074, -2.3938, -2.4110, -2.2644, -2.0972, -2.2697, -2.4230, -2.4061,\n",
              "         -2.4689, -2.2643],\n",
              "        [-2.1169, -2.3318, -2.3928, -2.2431, -2.1180, -2.3446, -2.4332, -2.3491,\n",
              "         -2.4725, -2.2904],\n",
              "        [-2.1627, -2.3148, -2.3414, -2.3144, -2.1170, -2.2347, -2.4618, -2.4350,\n",
              "         -2.4612, -2.2487],\n",
              "        [-2.0478, -2.3826, -2.3885, -2.3223, -2.1904, -2.3108, -2.3992, -2.4047,\n",
              "         -2.4746, -2.1847],\n",
              "        [-2.0334, -2.3803, -2.3705, -2.3255, -2.1974, -2.2431, -2.4442, -2.4889,\n",
              "         -2.3980, -2.2303],\n",
              "        [-2.1268, -2.4402, -2.4364, -2.2195, -2.0626, -2.3399, -2.3749, -2.3393,\n",
              "         -2.4011, -2.3643],\n",
              "        [-2.0961, -2.3780, -2.3897, -2.3545, -2.1303, -2.2548, -2.4577, -2.4343,\n",
              "         -2.4265, -2.1856],\n",
              "        [-2.1186, -2.3831, -2.3521, -2.2545, -2.1131, -2.3443, -2.3467, -2.4005,\n",
              "         -2.4663, -2.3084],\n",
              "        [-2.1133, -2.2971, -2.3881, -2.3036, -2.1433, -2.2761, -2.4103, -2.3840,\n",
              "         -2.4682, -2.3000],\n",
              "        [-2.1317, -2.3786, -2.3138, -2.2669, -2.1746, -2.2975, -2.4288, -2.3614,\n",
              "         -2.4643, -2.2584],\n",
              "        [-2.0731, -2.4018, -2.3671, -2.2290, -2.1776, -2.2911, -2.4255, -2.4354,\n",
              "         -2.4123, -2.2810],\n",
              "        [-2.1184, -2.3444, -2.3772, -2.3450, -2.1228, -2.3762, -2.4536, -2.3237,\n",
              "         -2.4059, -2.2206],\n",
              "        [-2.1080, -2.3351, -2.3458, -2.3719, -2.1390, -2.2905, -2.4214, -2.3830,\n",
              "         -2.3929, -2.2905],\n",
              "        [-2.0230, -2.4028, -2.4370, -2.3201, -2.1207, -2.3362, -2.4281, -2.3568,\n",
              "         -2.4179, -2.2739],\n",
              "        [-2.1686, -2.2934, -2.3916, -2.2971, -2.1034, -2.3397, -2.3679, -2.3712,\n",
              "         -2.4294, -2.3108],\n",
              "        [-2.0652, -2.4266, -2.3560, -2.2848, -2.1059, -2.2999, -2.3805, -2.3905,\n",
              "         -2.5074, -2.2956],\n",
              "        [-2.0934, -2.3984, -2.3758, -2.1894, -2.1668, -2.2882, -2.4174, -2.3732,\n",
              "         -2.4598, -2.3313],\n",
              "        [-2.1248, -2.4117, -2.3375, -2.3054, -2.0944, -2.3571, -2.4615, -2.3991,\n",
              "         -2.4098, -2.1999],\n",
              "        [-2.0912, -2.3678, -2.3990, -2.2652, -2.1430, -2.3390, -2.4442, -2.4121,\n",
              "         -2.4194, -2.2162],\n",
              "        [-2.1603, -2.3407, -2.3104, -2.3654, -2.1390, -2.2402, -2.3910, -2.4194,\n",
              "         -2.4541, -2.2572],\n",
              "        [-2.0486, -2.4325, -2.3948, -2.3211, -2.0837, -2.2499, -2.4355, -2.3976,\n",
              "         -2.5504, -2.2303],\n",
              "        [-2.1124, -2.4010, -2.3823, -2.2700, -2.0907, -2.4229, -2.3353, -2.3521,\n",
              "         -2.4260, -2.3008],\n",
              "        [-2.0978, -2.3612, -2.3998, -2.3090, -2.1644, -2.3289, -2.4384, -2.3594,\n",
              "         -2.3852, -2.2367],\n",
              "        [-2.0737, -2.4188, -2.3930, -2.2688, -2.0965, -2.2583, -2.4955, -2.3849,\n",
              "         -2.4982, -2.2417],\n",
              "        [-1.9986, -2.4039, -2.4299, -2.2885, -2.1729, -2.3520, -2.4309, -2.4103,\n",
              "         -2.4320, -2.2072],\n",
              "        [-2.0931, -2.3999, -2.3900, -2.2864, -2.0837, -2.2810, -2.3840, -2.4149,\n",
              "         -2.4550, -2.3164],\n",
              "        [-2.1250, -2.3544, -2.3758, -2.3418, -2.0782, -2.2679, -2.5274, -2.3863,\n",
              "         -2.4640, -2.1989],\n",
              "        [-2.1198, -2.3238, -2.3916, -2.2907, -2.1037, -2.3071, -2.4003, -2.4423,\n",
              "         -2.4247, -2.2861],\n",
              "        [-2.1201, -2.3821, -2.3247, -2.2337, -2.1178, -2.3269, -2.3999, -2.4657,\n",
              "         -2.4138, -2.3063],\n",
              "        [-2.0572, -2.4517, -2.3604, -2.2895, -2.1265, -2.3329, -2.3642, -2.3873,\n",
              "         -2.4924, -2.2494],\n",
              "        [-2.1318, -2.3193, -2.3980, -2.2935, -2.0905, -2.2866, -2.4278, -2.3610,\n",
              "         -2.4649, -2.3187],\n",
              "        [-2.0816, -2.3874, -2.3561, -2.4168, -2.0677, -2.3430, -2.3543, -2.4278,\n",
              "         -2.4229, -2.2536],\n",
              "        [-2.1436, -2.3574, -2.3963, -2.2395, -2.0785, -2.2914, -2.4285, -2.3796,\n",
              "         -2.4758, -2.3083],\n",
              "        [-2.1106, -2.4167, -2.3617, -2.3020, -2.0969, -2.3122, -2.5244, -2.3440,\n",
              "         -2.4172, -2.2238],\n",
              "        [-2.1349, -2.3880, -2.4040, -2.2794, -2.1073, -2.3488, -2.4053, -2.3256,\n",
              "         -2.4030, -2.2851],\n",
              "        [-2.0577, -2.4313, -2.3816, -2.2645, -2.0612, -2.3687, -2.3864, -2.4058,\n",
              "         -2.5144, -2.2625],\n",
              "        [-2.0956, -2.3190, -2.4041, -2.3503, -2.1418, -2.3075, -2.4360, -2.3227,\n",
              "         -2.4748, -2.2415],\n",
              "        [-2.0790, -2.4406, -2.3200, -2.2758, -2.1170, -2.2923, -2.3864, -2.4337,\n",
              "         -2.4486, -2.3094],\n",
              "        [-2.1338, -2.3231, -2.3556, -2.3413, -2.1135, -2.3140, -2.4294, -2.3442,\n",
              "         -2.4351, -2.2895],\n",
              "        [-2.1061, -2.3869, -2.3075, -2.3216, -2.0921, -2.3392, -2.4033, -2.3773,\n",
              "         -2.4582, -2.3015],\n",
              "        [-2.0639, -2.3504, -2.4139, -2.3283, -2.1020, -2.3398, -2.4520, -2.3880,\n",
              "         -2.4526, -2.2236],\n",
              "        [-2.0381, -2.3956, -2.4240, -2.3013, -2.1243, -2.3078, -2.3363, -2.4653,\n",
              "         -2.4480, -2.2752],\n",
              "        [-2.1305, -2.3483, -2.3763, -2.3351, -2.1106, -2.3502, -2.3687, -2.3828,\n",
              "         -2.4698, -2.2165],\n",
              "        [-2.1275, -2.3600, -2.3551, -2.2460, -2.1226, -2.3277, -2.4029, -2.3934,\n",
              "         -2.4827, -2.2710],\n",
              "        [-2.1182, -2.3731, -2.3587, -2.2319, -2.2218, -2.3248, -2.4066, -2.3335,\n",
              "         -2.4190, -2.2789],\n",
              "        [-2.0761, -2.3904, -2.3674, -2.2658, -2.1377, -2.3011, -2.3879, -2.4248,\n",
              "         -2.4399, -2.3032],\n",
              "        [-2.0881, -2.3953, -2.3405, -2.2428, -2.1712, -2.2691, -2.4296, -2.4124,\n",
              "         -2.4128, -2.3247],\n",
              "        [-2.1424, -2.3044, -2.3572, -2.3265, -2.1419, -2.3085, -2.4222, -2.3414,\n",
              "         -2.4673, -2.2642],\n",
              "        [-2.0690, -2.4028, -2.4003, -2.2714, -2.0839, -2.3546, -2.3734, -2.4045,\n",
              "         -2.4575, -2.2939],\n",
              "        [-2.1742, -2.2889, -2.3448, -2.3094, -2.1569, -2.3113, -2.4331, -2.3777,\n",
              "         -2.4682, -2.2104],\n",
              "        [-2.1616, -2.3172, -2.3477, -2.2979, -2.1291, -2.3047, -2.4543, -2.4407,\n",
              "         -2.4408, -2.1947],\n",
              "        [-2.0393, -2.4157, -2.4011, -2.2956, -2.1049, -2.2924, -2.3856, -2.4209,\n",
              "         -2.5065, -2.2639],\n",
              "        [-2.0801, -2.3976, -2.4065, -2.2711, -2.0748, -2.3487, -2.4270, -2.3679,\n",
              "         -2.4622, -2.2777],\n",
              "        [-2.1575, -2.2732, -2.3420, -2.3884, -2.1697, -2.2859, -2.4302, -2.4270,\n",
              "         -2.4163, -2.1891],\n",
              "        [-2.1502, -2.3474, -2.3428, -2.2818, -2.1398, -2.3299, -2.3413, -2.4052,\n",
              "         -2.3981, -2.3286],\n",
              "        [-2.0857, -2.3725, -2.3970, -2.2885, -2.1520, -2.2945, -2.3341, -2.3574,\n",
              "         -2.4935, -2.3140],\n",
              "        [-2.1293, -2.3502, -2.3586, -2.3109, -2.0363, -2.2889, -2.4635, -2.3638,\n",
              "         -2.5003, -2.3141],\n",
              "        [-2.0336, -2.3733, -2.4156, -2.4199, -2.1017, -2.2920, -2.5390, -2.4512,\n",
              "         -2.3779, -2.1495]], grad_fn=<LogSoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3wg1_bn92wF"
      },
      "source": [
        "## Autograd\n",
        "\n",
        "* 이제 loss function을 정의하고 loss 값을 구하는 방법을 알았으니, training (최적 parameter)을 찾기위한 작업을 수행합니다\n",
        "* 우리는 최적화 과정은 SGD (또는 유사 변형 알고리즘)를 통해서 수행하게 되는데, SGD를 수행하기 위해서는 또 Gradient를 구해야 한다는 것을 알고 있습니다\n",
        "* Pytorch의 가장 큰 장점은, 이런 gradient를 자동으로 구하기 위한 `autograd` 모듈을 제공합니다 (!!!!)\n",
        "* 내부적으로는 각 tensor가 어떤 변환은 격는지 기록을 통해서, 다시 각 연산을 역순 (backward)으로 gradient를 구하게 됩니다\n",
        "* 이런 과정을 backpropagation이라고 하는데, 나중에 더욱 자세히 배우도록 하고, 본 실습에서는 `autograd`모듈이 자동으로 계산해준다고 알고 사용하면 됩니다\n",
        "* Pytorch에서 tensor에 수행되는 연산을 기록하고자 할때 사용하는 중요한 keyword가 `requires_grad`이며, 사용 방법은 `x.requires_grad_(True)`\n",
        "\n",
        "* Training을 모두 끝내고, test단계에서는 gradient update을 하지 않기 때문에 불필요한 메모리/연산을 줄이기 위해서, gradient 연산에 필요한 연산과정 저장을 끄기 위해서 `torch.no_grad()`로 gradient를 비활성화 할 수 있습니다\n",
        "\n",
        "```python\n",
        "x = torch.zeros(1, requires_grad=True)\n",
        ">>> with torch.no_grad():\n",
        "...     y = x * 2\n",
        ">>> y.requires_grad\n",
        "False\n",
        "```\n",
        "\n",
        "* 비슷하게 gradient를 활성/비활성화를 `torch.set_grad_enabled(True|False)`를 통해서 할 수도 있습니다\n",
        "\n",
        "Gradient를 연산할때는 해당 tensor에 대해서 수행하며, 예를들어서 `z` tensor에 `z.backward()`라는 명령을 주면 gradient를 구합니다\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKL-mvII92wG",
        "outputId": "51852ae9-1e0f-4b5d-998b-b2025b962a79"
      },
      "source": [
        "x = torch.randn(1,4, requires_grad=True)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1.5996, -1.3183, -1.8123, -0.3593]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URyUNyzt92wH",
        "outputId": "179c0f83-160a-4b16-fdcf-ae25eab067df"
      },
      "source": [
        "y = x**2\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2.5588, 1.7379, 3.2844, 0.1291]], grad_fn=<PowBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEOjRrVZ92wH"
      },
      "source": [
        "* grad_fn을 통해서 `y` variable를 만들어낸 operation `PowBackward0`를 확인할 수 있다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-ta0tJN92wH",
        "outputId": "d31876a2-b570-4f21-b05f-8f214037bf09"
      },
      "source": [
        "## grad_fn shows the function that generated this variable\n",
        "print(y.grad_fn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PowBackward0 object at 0x0000022C04799748>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yo2Y6Df292wI"
      },
      "source": [
        "* autograd module은 위와 같은 operation 정보를 저장하면서, 각 operation에 대해서 gradient를 연산하는 방법을 갖고 있습니다\n",
        "* 위 과정을 미분에서 chain rule과 같은 형태의 연산을 통해서 gradient를 연산합니다\n",
        "* Gradient를 구하기 위해서 y tensor를 scalar 값으로 변환하는 연산을 추가해보죠"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qGmWcLX92wI",
        "outputId": "9e44b884-dd98-405b-9279-f1f30bd872ca"
      },
      "source": [
        "z = y.mean()\n",
        "print(z)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.9275, grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnnJgLG_92wJ"
      },
      "source": [
        "* `x`와 `y`의 gradient를 구해볼 수 있는데, 아직은 비어있습니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHtmlvZs92wJ",
        "outputId": "6f98a07e-feca-40cd-ed83-5933dc554307"
      },
      "source": [
        "print(x.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-p__ygw92wJ"
      },
      "source": [
        "* Gradient를 구하기 위해서 연산을 수행하고자 하는 variable에 `.backward` method를 실행합니다\n",
        "  * 예를 들어서 `z`에 z.backward()를 실행하면 $\\nabla_x z$를 구하게 되죠\n",
        "\n",
        "\\begin{align*}\n",
        "\\nabla_x z = \\nabla_x \\left[\\frac{1}{n}\\sum_i^n x_i^2\\right] &= \\left[\\frac{\\partial z}{\\partial x_1}, \\cdots,\\frac{\\partial z}{\\partial x_4}\\right]\\\\\n",
        "&=\\left[\\frac{x_1}{2},\\ldots,\\frac{x_4}{2}\\right]\n",
        "\\end{align*}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ie_MqoLS92wK",
        "outputId": "42399afd-61c3-4766-946a-b41ee6507ee8"
      },
      "source": [
        "z.backward()\n",
        "print(x.grad)\n",
        "print(x/2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.2210,  0.1333,  0.4016,  0.0818]])\n",
            "tensor([[-0.2210,  0.1333,  0.4016,  0.0818]], grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MW-14lB892wK"
      },
      "source": [
        "* 위와 같이 gradient를 구할 수 있으면, gradient descent를 수행할 수 있습니다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxmKvN-o92wK"
      },
      "source": [
        "## Loss and Autograd together\n",
        "\n",
        "* Pytorch를 통해서 network를 설계할때에, 모든 parameter들은 `requires_grad = True` 상태로 초기화 됩니다\n",
        "* 이는, 최종적으로 forward pass output 값고 label 값을 통해서 `loss`를 계산하고, `loss.backward()`를 실행하여 loss function에 대한 gradient가 계산된다\n",
        "* 아래 예제를 통해서 gradient를 구하는 방법에 대한 예이다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Nr33T8D92wL"
      },
      "source": [
        "# Build a feed-forward network\n",
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "images, labels = next(iter(trainloader))\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "logps = model(images)\n",
        "loss = criterion(logps, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6N6X4w0V92wM",
        "outputId": "14435df9-4814-4ae9-93e0-dbaf8e1f2073"
      },
      "source": [
        "print(logps[0,:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-2.4375, -2.4787, -2.3244, -2.3363, -2.5731, -2.0715, -2.2147, -2.1522,\n",
            "        -2.2507, -2.2906], grad_fn=<SliceBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8BX1MPw92wM",
        "outputId": "397e92da-0cc8-45bc-968f-d92c823290bc"
      },
      "source": [
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 1, 2, 9, 2, 3, 6, 9, 3, 7, 7, 2, 6, 4, 3, 2, 9, 5, 1, 2, 2, 7, 5, 3,\n",
            "        4, 9, 9, 7, 1, 1, 6, 9, 5, 8, 3, 8, 7, 8, 6, 5, 3, 7, 1, 3, 1, 9, 2, 7,\n",
            "        2, 6, 0, 1, 2, 5, 9, 0, 6, 8, 9, 1, 9, 3, 7, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9F15LUrI92wN",
        "outputId": "4b6943d7-5c2b-4d78-bb38-6cd5da2a90cb"
      },
      "source": [
        "criterion(logps, labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.3012, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSLZI_JM92wN",
        "outputId": "1aa2dc8a-9159-479b-b046-bbb25ba8b56b"
      },
      "source": [
        "print('Before backward pass: \\n', model[0].weight.grad)\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print('After backward pass: \\n', model[0].weight.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before backward pass: \n",
            " None\n",
            "After backward pass: \n",
            " tensor([[ 0.0061,  0.0061,  0.0061,  ...,  0.0061,  0.0061,  0.0061],\n",
            "        [ 0.0045,  0.0045,  0.0045,  ...,  0.0045,  0.0045,  0.0045],\n",
            "        [-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0019, -0.0019, -0.0019,  ..., -0.0019, -0.0019, -0.0019],\n",
            "        [-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8OiUPHq92wO"
      },
      "source": [
        "## Training the network!\n",
        "\n",
        "\n",
        "* 자, 그럼 network parameter에 대한 loss function의 gradient를 구했으니, 이제 최적화를 할 수 있습니다\n",
        "* 최적화 기법은 SGD 이외에도 많으며 (SGD의 변형들임) [`optim` package](https://pytorch.org/docs/stable/optim.html)에서 찾아서 사용할 수 있습니다\n",
        "* 예를 들어서 SGD는 `optim.SGD`를 통해서 불러올 수 있습니다\n",
        "* 아래 예를 보죠"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRh0_TY992wP"
      },
      "source": [
        "from torch import optim\n",
        "\n",
        "# Optimizers require the parameters to optimize and a learning rate\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Arbzy0Oi92wP"
      },
      "source": [
        "* model.parameters()는 우리 network의 모든 training parameter이며, lr는 learning rate 입니다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6bKZr8692wP"
      },
      "source": [
        "* 자, 이제 traning에 필요한 모든 부분이 준비되었습니다\n",
        "* 전체 데이터에 대한 training은 숙제로 하고, 한 batch만 수행하는 과정을 살펴보죠\n",
        "* Pytorch에서 training의 전체 흐름은 다음과 같습니다:\n",
        "\n",
        "1. Network에서 forward pass\n",
        "2. Foward pass를 통해서 얻은 output을 활용하여 loss를 구한다\n",
        "3. Gradient를 구하기 위해서 `loss.backward()`를 실행한다\n",
        "4. Optimizer에서 weight를 한번 update 한다 (SGD의 경우 한 batch에 대해서 한번 update)\n",
        "\n",
        "**[중요]**\n",
        "* 한가지 주의할 점은, 한 Parameter들에 대해서 gradient를 여러개 구해야하는 경우, (예, batch 처리) gradient 값들은 계속 추가적으로 저장됩니다\n",
        "  * 다시말해서, sample 별로 gradient를 구한다고 생각하면, 한 batch에 여러 sample이 있으니, gradient를 여러개 구해야함\n",
        "* 한번 parameter update가 끝났으면, gradient 값을 초기화해야, 새로운 batch에 대한 새 gradient 값을 계산 합니다\n",
        "* 이를 위해서 batch 시작시에 `optimizer.zero_grad()`를 실행해줘야합니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjSvyAES92wQ",
        "outputId": "0283b32b-c3c8-48c4-87d9-cb515aa784a3"
      },
      "source": [
        "print('Initial weights - ', model[0].weight)\n",
        "\n",
        "images, labels = next(iter(trainloader))\n",
        "images.resize_(64, 784)\n",
        "\n",
        "# Clear the gradients, do this because gradients are accumulated\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# Forward pass, then backward pass, then update weights\n",
        "output = model(images)\n",
        "loss = criterion(output, labels)\n",
        "loss.backward()\n",
        "print('Gradient -', model[0].weight.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial weights -  Parameter containing:\n",
            "tensor([[ 0.0244, -0.0335, -0.0249,  ..., -0.0150, -0.0118, -0.0239],\n",
            "        [-0.0324,  0.0214,  0.0146,  ..., -0.0029,  0.0069, -0.0310],\n",
            "        [-0.0059,  0.0336,  0.0250,  ..., -0.0198,  0.0149, -0.0047],\n",
            "        ...,\n",
            "        [-0.0273, -0.0228,  0.0296,  ...,  0.0198, -0.0224,  0.0232],\n",
            "        [ 0.0191,  0.0018, -0.0197,  ...,  0.0242, -0.0323,  0.0089],\n",
            "        [-0.0199,  0.0051, -0.0140,  ...,  0.0251,  0.0330,  0.0072]],\n",
            "       requires_grad=True)\n",
            "Gradient - tensor([[ 3.2655e-04,  3.2655e-04,  3.2655e-04,  ...,  3.2655e-04,\n",
            "          3.2655e-04,  3.2655e-04],\n",
            "        [-1.2224e-03, -1.2224e-03, -1.2224e-03,  ..., -1.2224e-03,\n",
            "         -1.2224e-03, -1.2224e-03],\n",
            "        [-2.8441e-05, -2.8441e-05, -2.8441e-05,  ..., -2.8441e-05,\n",
            "         -2.8441e-05, -2.8441e-05],\n",
            "        ...,\n",
            "        [ 3.3719e-05,  3.3719e-05,  3.3719e-05,  ...,  3.3719e-05,\n",
            "          3.3719e-05,  3.3719e-05],\n",
            "        [-7.4700e-04, -7.4700e-04, -7.4700e-04,  ..., -7.4700e-04,\n",
            "         -7.4700e-04, -7.4700e-04],\n",
            "        [-1.6851e-03, -1.6851e-03, -1.6851e-03,  ..., -1.6851e-03,\n",
            "         -1.6851e-03, -1.6851e-03]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsJOCmN992wQ",
        "outputId": "7b4091e7-1cce-4519-fd0a-cd010499db1b"
      },
      "source": [
        "# Take an update step and few the new weights\n",
        "optimizer.step()\n",
        "print('Updated weights - ', model[0].weight)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated weights -  Parameter containing:\n",
            "tensor([[ 0.0244, -0.0335, -0.0249,  ..., -0.0150, -0.0118, -0.0239],\n",
            "        [-0.0324,  0.0214,  0.0146,  ..., -0.0029,  0.0069, -0.0310],\n",
            "        [-0.0059,  0.0336,  0.0250,  ..., -0.0198,  0.0149, -0.0047],\n",
            "        ...,\n",
            "        [-0.0273, -0.0228,  0.0296,  ...,  0.0198, -0.0224,  0.0232],\n",
            "        [ 0.0191,  0.0018, -0.0197,  ...,  0.0242, -0.0323,  0.0089],\n",
            "        [-0.0199,  0.0052, -0.0140,  ...,  0.0251,  0.0330,  0.0072]],\n",
            "       requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6HsdIAU92wR"
      },
      "source": [
        "### Training for real\n",
        "\n",
        "> **Exercise 2 [20 points]:** \n",
        "1. 아래 loop 안에 training을 위한 코드를 완성하세요\n",
        "2. epoch는 전체 dataset을 한번 읽으면 1씩 증가합나다\n",
        "3. 총 5번 dataset을 사용하여 training을 수행한다는 뜻입니다\n",
        "4. 2번째 for loop은 batch 에 대한 for loop 입니다\n",
        "5. 각 batch마다 SGD (batch SGD)를 수행하도록 위에서 배운 모듈들을 사용하여 완성하세요\n",
        "\n",
        "`output`\n",
        "```python\n",
        "Training loss: 1.869339931112871\n",
        "Training loss: 0.7947963790090353\n",
        "Training loss: 0.5183348833307274\n",
        "Training loss: 0.4340690239342545\n",
        "Training loss: 0.39035963734139256\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X15qrJNS92wR",
        "outputId": "17734ac1-a1d0-4d22-c8a6-5624c159452a"
      },
      "source": [
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
        "\n",
        "epochs = 5\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in trainloader:\n",
        "        # Flatten MNIST images into a 784 long vector\n",
        "        images = images.view(images.shape[0], -1)\n",
        "    \n",
        "        # TODO: Training pass\n",
        "        images, labels = next(iter(trainloader)) # images와 labels에 data를 가져옴\n",
        "        images.resize_(64, 784) # images를 (64, 784) 크기로 변경\n",
        "        optimizer.zero_grad() # 새로운 batch에 대한 새 gradient 값을 계산하기위해 gradient 값을 초기화\n",
        "\n",
        "        output = model(images) # images를 이용하여 네트워크에서 Forward pass -> output을 구함\n",
        "        loss = criterion(output, labels) # output과 labels 로 NLLLoss 사용하여 loss 계산\n",
        "        loss.backward() # gredient를 구하기위해 backward 실행\n",
        "\n",
        "        # Take an update step and few the new weights\n",
        "        optimizer.step() # optimizer 를 update (weight 들이 업데이트됨)\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss: 1.9003826880505852\n",
            "Training loss: 0.8439655472983175\n",
            "Training loss: 0.5218663980235169\n",
            "Training loss: 0.4259909618892141\n",
            "Training loss: 0.38454588988760136\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-bju_KF92wR",
        "outputId": "57f9a189-8e93-49a1-df65-261e45b97236"
      },
      "source": [
        "%matplotlib inline\n",
        "import helper\n",
        "\n",
        "images, labels = next(iter(trainloader))\n",
        "\n",
        "img = images[0].view(1, 784)\n",
        "# Turn off gradients to speed up this part\n",
        "with torch.no_grad():\n",
        "    logps = model(img)\n",
        "\n",
        "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
        "ps = torch.exp(logps)\n",
        "helper.view_classify(img.view(1, 28, 28), ps)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtYrk2Ra92wS"
      },
      "source": [
        "Now our network is brilliant. It can accurately predict the digits in our images. Next up you'll write the code for training a neural network on a more complex dataset."
      ]
    }
  ]
}